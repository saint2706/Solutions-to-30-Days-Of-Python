{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2af919",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Day 16: File Handling for Business Analytics\n",
    "\n",
    "A huge part of data analysis involves reading data from files and writing results to them. Whether you're processing a sales report, a customer list, or log files, you need to interact with the file system. Python makes this easy.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Opening Files:** Use the `open()` function to open a file. It's best practice to use it with a `with` statement, which automatically closes the file for you, even if errors occur.\n",
    "  ```python\n",
    "  with open('my_report.txt', 'r') as file:\n",
    "      content = file.read()\n",
    "  ```\n",
    "- **File Modes:**\n",
    "  - `'r'`: Read (default). Throws an error if the file doesn't exist.\n",
    "  - `'w'`: Write. Creates a new file or overwrites an existing one.\n",
    "  - `'a'`: Append. Adds content to the end of an existing file.\n",
    "- **Exception Handling:** When working with files, it's crucial to wrap your code in a `try...except FileNotFoundError` block to handle cases where a file might be missing.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `fh.py`, has been refactored to provide several powerful, reusable functions for common business file-handling tasks.\n",
    "\n",
    "1. **Review the Code:** Open `Day_16_File_Handling/fh.py`. Examine functions like `count_words_and_lines()`, `find_most_common_words()`, `extract_emails_from_file()`, and `analyze_sales_csv()`.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script. It will create a few temporary demo files, run the analysis functions on them, print the results, and then clean up the files.\n",
    "   ```bash\n",
    "   python Day_16_File_Handling/fh.py\n",
    "   ```\n",
    "1. **Run the Tests:** The tests for this lesson are more advanced. They create temporary files in memory to test the functions without needing actual files on your disk.\n",
    "   ```bash\n",
    "   pytest tests/test_day_16.py\n",
    "   ```\n",
    "\n",
    "## ğŸ’» Exercises: Day 16\n",
    "\n",
    "1. **Analyze a Text File:**\n",
    "\n",
    "   - In a new script (`my_solutions_16.py`), create a simple text file named `my_memo.txt` and write a few sentences into it.\n",
    "   - Import the `count_words_and_lines` and `find_most_common_words` functions from the lesson script.\n",
    "   - Call these functions with your new file's path and print the results.\n",
    "\n",
    "1. **Process a Simple CSV:**\n",
    "\n",
    "   - Create a function `create_sales_data(filepath, sales_data)` that takes a list of lists and writes it to a CSV file.\n",
    "   - Your `sales_data` could be `[['Product', 'Price', 'Quantity'], ['Widget A', '10.00', '50'], ['Widget B', '15.50', '30']]`.\n",
    "   - Import and use the `analyze_sales_csv` function from the lesson to read your new CSV and print the total revenue and average transaction value.\n",
    "\n",
    "ğŸ‰ **Excellent!** You can now programmatically read from and write to the most common file types. This is a fundamental skill for automating data intake, processing reports, and saving your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e43149",
   "metadata": {},
   "source": [
    "Day 16: File Handling - Solutions\n",
    "\n",
    "This file contains comprehensive solutions to all Day 16 exercises,\n",
    "demonstrating advanced file handling techniques for business analytics.\n",
    "\n",
    "Author: 50 Days of Python Course\n",
    "Purpose: Educational solutions for MBA students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "from typing import List, Dict\n",
    "from fh import (\n",
    "    counter,\n",
    "    find_most_common_words,\n",
    "    extract_emails,\n",
    "    check_email,\n",
    ")\n",
    "\n",
    "\n",
    "def exercise_1_document_analyzer():\n",
    "    \"\"\"\n",
    "    Exercise 1: Document Statistics Analyzer\n",
    "\n",
    "    Creates and analyzes a sample story file, then demonstrates\n",
    "    batch processing of multiple business documents.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“Š EXERCISE 1: Document Statistics Analyzer\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create sample story file\n",
    "    story_content = \"\"\"\n",
    "    Once upon a time in a bustling corporate office, there lived a data analyst named Sarah.\n",
    "    Sarah worked tirelessly to transform raw business data into meaningful insights.\n",
    "    Every morning, she would arrive early to review the previous day's sales reports.\n",
    "    \n",
    "    The company had been struggling with declining market share.\n",
    "    Sarah believed that data-driven decisions could turn the tide.\n",
    "    She spent hours analyzing customer feedback, sales trends, and market research.\n",
    "    \n",
    "    One day, Sarah discovered a pattern in the data that nobody had noticed before.\n",
    "    Customer satisfaction was directly correlated with response time to support tickets.\n",
    "    This insight led to a complete overhaul of the customer service process.\n",
    "    \n",
    "    Within six months, the company's customer retention improved by 35%.\n",
    "    Sarah's analytical skills had literally saved the company millions of dollars.\n",
    "    Her story became legend in the data analytics community.\n",
    "    \"\"\"\n",
    "\n",
    "    # Write story to file\n",
    "    story_file = \"my_story.txt\"\n",
    "    try:\n",
    "        with open(story_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(story_content.strip())\n",
    "        print(f\"âœ… Created story file: {story_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating story file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Analyze the story\n",
    "    try:\n",
    "        words, lines = counter(story_file)\n",
    "        print(\"\\nğŸ“ˆ Story Analysis Results:\")\n",
    "        print(f\"   ğŸ“ Total words: {words}\")\n",
    "        print(f\"   ğŸ“„ Total lines: {lines}\")\n",
    "        print(f\"   ğŸ“Š Average words per line: {words / lines:.2f}\")\n",
    "\n",
    "        # Find most common words in the story\n",
    "        common_words = find_most_common_words(story_file, 5)\n",
    "        print(\"\\nğŸ”¤ Most Common Words:\")\n",
    "        for i, (freq, word) in enumerate(common_words, 1):\n",
    "            print(f\"   {i}. '{word}': {freq} times\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error analyzing story: {e}\")\n",
    "\n",
    "    # Demonstrate batch document analysis\n",
    "    print(\"\\nğŸ“š Batch Document Analysis:\")\n",
    "    batch_analyze_business_documents()\n",
    "\n",
    "    # Clean up\n",
    "    if os.path.exists(story_file):\n",
    "        os.remove(story_file)\n",
    "        print(f\"ğŸ§¹ Cleaned up: {story_file}\")\n",
    "\n",
    "\n",
    "def batch_analyze_business_documents():\n",
    "    \"\"\"\n",
    "    Advanced function for analyzing multiple business documents\n",
    "    \"\"\"\n",
    "    # Look for sample files in the data directory\n",
    "    data_dir = os.path.join(\"..\", \"data\")\n",
    "\n",
    "    # Common business document patterns\n",
    "    text_patterns = [\"*.txt\"]\n",
    "    sample_files = []\n",
    "\n",
    "    for pattern in text_patterns:\n",
    "        files = glob.glob(os.path.join(data_dir, pattern))\n",
    "        sample_files.extend(files)\n",
    "\n",
    "    if not sample_files:\n",
    "        print(\"   â„¹ï¸  No sample text files found for batch analysis\")\n",
    "        return\n",
    "\n",
    "    print(f\"   ğŸ“ Found {len(sample_files)} document(s) for analysis\")\n",
    "\n",
    "    total_words = 0\n",
    "    total_lines = 0\n",
    "    all_themes = {}\n",
    "\n",
    "    for file_path in sample_files[:3]:  # Limit to first 3 files\n",
    "        try:\n",
    "            print(f\"   ğŸ” Analyzing: {os.path.basename(file_path)}\")\n",
    "            words, lines = counter(file_path)\n",
    "            total_words += words\n",
    "            total_lines += lines\n",
    "\n",
    "            # Extract themes\n",
    "            themes = find_most_common_words(file_path, 3)\n",
    "            for freq, word in themes:\n",
    "                if len(word) > 3:  # Filter short words\n",
    "                    all_themes[word] = all_themes.get(word, 0) + freq\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "    if total_words > 0:\n",
    "        print(\"\\n   ğŸ“Š Batch Analysis Summary:\")\n",
    "        print(f\"      ğŸ“ Total words across documents: {total_words:,}\")\n",
    "        print(f\"      ğŸ“„ Total lines across documents: {total_lines:,}\")\n",
    "\n",
    "        # Top themes across all documents\n",
    "        if all_themes:\n",
    "            top_themes = sorted(all_themes.items(), key=lambda x: x[1], reverse=True)[\n",
    "                :5\n",
    "            ]\n",
    "            print(\"      ğŸ¯ Common themes across documents:\")\n",
    "            for i, (word, freq) in enumerate(top_themes, 1):\n",
    "                print(f\"         {i}. '{word}': {freq} mentions\")\n",
    "\n",
    "\n",
    "def exercise_2_contact_management():\n",
    "    \"\"\"\n",
    "    Exercise 2: Customer Contact Management System\n",
    "\n",
    "    Demonstrates email extraction and contact database creation.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“§ EXERCISE 2: Customer Contact Management System\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Look for email files in data directory\n",
    "    data_dir = os.path.join(\"..\", \"data\")\n",
    "    email_files = [\n",
    "        os.path.join(data_dir, \"email_exchanges.txt\"),\n",
    "        os.path.join(data_dir, \"email_exchanges_big.txt\"),\n",
    "    ]\n",
    "\n",
    "    all_emails = []\n",
    "    contact_database = {}\n",
    "    processed_files = []\n",
    "\n",
    "    for file_path in email_files:\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                print(f\"ğŸ” Processing: {os.path.basename(file_path)}\")\n",
    "                emails = extract_emails(file_path)\n",
    "\n",
    "                valid_emails = []\n",
    "                for email in emails:\n",
    "                    if check_email(email):\n",
    "                        valid_emails.append(email)\n",
    "\n",
    "                        # Organize by domain\n",
    "                        domain = email.split(\"@\")[1].lower()\n",
    "                        if domain not in contact_database:\n",
    "                            contact_database[domain] = []\n",
    "                        contact_database[domain].append(email)\n",
    "                        all_emails.append(email)\n",
    "\n",
    "                processed_files.append(file_path)\n",
    "                print(f\"   âœ… Found {len(valid_emails)} valid email addresses\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error processing {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"   â„¹ï¸  File not found: {os.path.basename(file_path)}\")\n",
    "\n",
    "    if all_emails:\n",
    "        # Remove duplicates\n",
    "        unique_emails = list(set(all_emails))\n",
    "\n",
    "        print(\"\\nğŸ“Š Contact Management Summary:\")\n",
    "        print(f\"   ğŸ“§ Total email addresses found: {len(all_emails)}\")\n",
    "        print(f\"   ğŸ”„ Unique email addresses: {len(unique_emails)}\")\n",
    "        print(f\"   ğŸ¢ Companies/domains: {len(contact_database)}\")\n",
    "\n",
    "        print(\"\\nğŸ¢ Contact Database by Domain:\")\n",
    "        for domain, emails in sorted(contact_database.items()):\n",
    "            unique_domain_emails = list(set(emails))\n",
    "            print(f\"   ğŸ“ {domain}: {len(unique_domain_emails)} contacts\")\n",
    "            for email in unique_domain_emails[:3]:  # Show first 3\n",
    "                print(f\"      â€¢ {email}\")\n",
    "            if len(unique_domain_emails) > 3:\n",
    "                print(f\"      ... and {len(unique_domain_emails) - 3} more\")\n",
    "\n",
    "        # Export contacts to CSV\n",
    "        export_contacts_to_csv(contact_database)\n",
    "    else:\n",
    "        print(\"   â„¹ï¸  No email addresses found in available files\")\n",
    "\n",
    "\n",
    "def export_contacts_to_csv(contact_database: Dict[str, List[str]]):\n",
    "    \"\"\"\n",
    "    Export contact database to CSV format for business use.\n",
    "    \"\"\"\n",
    "    csv_file = \"customer_contacts.csv\"\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Email\", \"Domain\", \"Company\"])\n",
    "\n",
    "            for domain, emails in contact_database.items():\n",
    "                unique_emails = list(set(emails))\n",
    "                for email in unique_emails:\n",
    "                    # Extract company name from domain (remove .com, .org, etc.)\n",
    "                    company = domain.split(\".\")[0].title()\n",
    "                    writer.writerow([email, domain, company])\n",
    "\n",
    "        print(f\"   ğŸ’¾ Exported contacts to: {csv_file}\")\n",
    "\n",
    "        # Clean up demonstration file\n",
    "        if os.path.exists(csv_file):\n",
    "            os.remove(csv_file)\n",
    "            print(\"   ğŸ§¹ Cleaned up demonstration file\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error exporting contacts: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run all Day 16 solutions and demonstrations.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ Day 16: File Handling for Business Analytics - Solutions\")\n",
    "    print(\"ğŸ“ 50 Days of Python for MBA Program\")\n",
    "    print(\"ğŸ“š Comprehensive demonstrations of file processing techniques\")\n",
    "\n",
    "    try:\n",
    "        # Run key exercises\n",
    "        exercise_1_document_analyzer()\n",
    "        exercise_2_contact_management()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ‰ All File Handling Exercises Completed Successfully!\")\n",
    "        print(\"ğŸ’¡ Key Skills Demonstrated:\")\n",
    "        print(\"   ğŸ“„ Text file processing and analysis\")\n",
    "        print(\"   ğŸ“Š Data extraction from multiple formats\")\n",
    "        print(\"   ğŸ“§ Email validation and contact management\")\n",
    "        print(\"   ğŸ” Document similarity and competitive analysis\")\n",
    "        print(\"   ğŸ“ˆ Technology trend tracking\")\n",
    "        print(\"   ğŸ—ï¸  Integrated business intelligence systems\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in main execution: {e}\")\n",
    "        print(\"ğŸ’¡ This may be due to missing sample files in the data directory\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# extract_unique_emails('../data/email_exchanges.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
