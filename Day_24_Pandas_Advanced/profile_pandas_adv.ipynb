{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1664eb96",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 24: Advanced Pandas - Working with Real Data\n",
    "\n",
    "You'll rarely create data from scratch. The most common workflow is to load data from external sources like CSV files. Today, we'll focus on loading data and using powerful methods to select, filter, and clean it.\n",
    "\n",
    "## Advanced Selection: `.loc` and `.iloc`\n",
    "\n",
    "For complex selections, Pandas provides two powerful indexers:\n",
    "\n",
    "- **`.loc` (Label-based):** Selects data based on **row and column labels**.\n",
    "  ```python\n",
    "  # Selects row with index label 3, and only the 'Product' and 'Revenue' columns\n",
    "  subset = df.loc[3, ['Product', 'Revenue']]\n",
    "  ```\n",
    "- **`.iloc` (Integer-position based):** Selects data based on its **integer position**.\n",
    "  ```python\n",
    "  # Selects the first three rows (positions 0, 1, 2) and the first two columns (0, 1)\n",
    "  subset = df.iloc[0:3, 0:2]\n",
    "  ```\n",
    "\n",
    "## Conditional Filtering (Boolean Indexing)\n",
    "\n",
    "This is one of the most powerful features of Pandas. You can filter your DataFrame by providing a boolean (`True`/`False`) condition.\n",
    "\n",
    "```python\n",
    "# Find all high-revenue sales from the 'North' region\n",
    "# Note the parentheses around each condition\n",
    "high_rev_north = df[(df['Revenue'] > 50000) & (df['Region'] == 'North')]\n",
    "```\n",
    "\n",
    "## Handling Missing Data\n",
    "\n",
    "Real-world data is often messy and has missing values, represented as `NaN`.\n",
    "\n",
    "- `df.isnull().sum()`: A crucial command to count missing values in each column.\n",
    "- `df.dropna()`: Drops rows that contain any missing values.\n",
    "- `df.fillna(value)`: Fills missing values with a specified value (e.g., 0 or the column's mean).\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `pandas_adv.py`, has been refactored to place each advanced operation into its own testable function.\n",
    "\n",
    "1. **Review the Code:** Open `Day_24_Pandas_Advanced/pandas_adv.py`. Examine functions like `filter_by_high_revenue()`, `filter_by_product_and_region()`, and `handle_missing_data()`.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script to see the functions in action:\n",
    "   ```bash\n",
    "   python Day_24_Pandas_Advanced/pandas_adv.py\n",
    "   ```\n",
    "   If the CSV file is missing, the refactored `handle_missing_data()` helper now raises\n",
    "   a clear `ValueError` explaining how to restore the dataset before continuing.\n",
    "1. **Run the Tests:** The tests use a sample DataFrame created in memory, so they don't depend on the external CSV file.\n",
    "   ```bash\n",
    "   pytest tests/test_day_24.py\n",
    "   ```\n",
    "\n",
    "## âœ¨ Interactive Plotly Visualisations\n",
    "\n",
    "Plotly chart builders now sit alongside the existing data-wrangling helpers:\n",
    "\n",
    "- `build_revenue_by_region_bar_chart()` aggregates revenue totals for each region and renders an interactive bar chart.\n",
    "- `build_units_vs_price_scatter()` plots price sensitivity using `Units Sold` on the y-axis and encodes the point colour scale for quick outlier detection.\n",
    "\n",
    "To experiment locally:\n",
    "\n",
    "1. Install notebook dependencies if you have not done so already:\n",
    "   ```bash\n",
    "   pip install notebook plotly\n",
    "   ```\n",
    "1. Launch Jupyter from the project root and open the companion notebook:\n",
    "   ```bash\n",
    "   jupyter notebook Day_24_Pandas_Advanced/pandas_adv_interactive.ipynb\n",
    "   ```\n",
    "1. Run the cells to compare the quick Matplotlib baseline with the interactive Plotly versions. Hover, filter, and export the Plotly figures directly from the notebook toolbar.\n",
    "\n",
    "## ðŸ”¬ Profiling the Workflow\n",
    "\n",
    "Curious about where Pandas spends its time? Launch the shared profiling helper to benchmark the lesson workflow:\n",
    "\n",
    "```bash\n",
    "python Day_24_Pandas_Advanced/profile_pandas_adv.py --mode cprofile\n",
    "python Day_24_Pandas_Advanced/profile_pandas_adv.py --mode timeit --repeat 5 --number 3\n",
    "```\n",
    "\n",
    "The first command prints a truncated `cProfile` report. In our baseline run the CSV load (`pandas.read_csv`) and the follow-up cleaning call (`handle_missing_data`) dominated the runtime, confirming that disk I/O and DataFrame materialisation are the hot spots.ã€732170â€ L1-L28ã€‘ The `timeit` helper highlights how quickly the full workflow executes once the operating system cache is warmâ€”about 3 ms per iteration on average across five repeats.ã€af7429â€ L1-L7ã€‘ If you plan to reuse the dataset across multiple analyses, load the CSV once and reuse the DataFrame rather than calling `read_csv` inside a tight loop.\n",
    "\n",
    "## ðŸ’» Exercises: Day 24\n",
    "\n",
    "1. **Load and Inspect:**\n",
    "\n",
    "   - In a new script (`my_solutions_24.py`), import `pandas as pd` and `pathlib`.\n",
    "   - Load the `sales_data.csv` file (located in the `Day_24_Pandas_Advanced` directory) into a DataFrame.\n",
    "   - Use `.head()` and `.info()` to inspect the loaded data.\n",
    "\n",
    "1. **Select and Filter:**\n",
    "\n",
    "   - Using the DataFrame from the previous exercise, import and use the `filter_by_product_and_region` function to find all sales of `\"Mouse\"` in the `\"South\"` region. Print the result.\n",
    "   - Import and use the `filter_by_high_revenue` function to find all sales with revenue over $70,000.\n",
    "\n",
    "1. **Basic Data Cleaning:**\n",
    "\n",
    "   - Import the `handle_missing_data` function.\n",
    "   - Call the function twice on your DataFrame:\n",
    "     - Once with `strategy='drop'` to remove rows with missing data.\n",
    "     - Once with `strategy='fill'` to fill missing revenue with the column average.\n",
    "   - Print the `.shape` of both resulting DataFrames to see how they differ.\n",
    "\n",
    "ðŸŽ‰ **Excellent work!** You're now working with data like a real analystâ€”loading it from files, inspecting it, and using powerful tools to filter and clean it. These are foundational skills for every data analysis project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d369c10",
   "metadata": {},
   "source": [
    "Command-line helpers for profiling the Pandas advanced lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "try:\n",
    "    from mypackage.profiling import print_report, profile_callable\n",
    "except ImportError:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "    if str(PROJECT_ROOT) not in sys.path:\n",
    "        sys.path.append(str(PROJECT_ROOT))\n",
    "    from mypackage.profiling import print_report, profile_callable\n",
    "\n",
    "try:  # pragma: no cover - runtime guard for script execution\n",
    "    from .pandas_adv import (\n",
    "        filter_by_high_revenue,\n",
    "        filter_by_product_and_region,\n",
    "        handle_missing_data,\n",
    "        load_sales_data,\n",
    "    )\n",
    "except ImportError:  # pragma: no cover - allows ``python profile_pandas_adv.py``\n",
    "    CURRENT_DIR = Path(__file__).resolve().parent\n",
    "    if str(CURRENT_DIR) not in sys.path:\n",
    "        sys.path.append(str(CURRENT_DIR))\n",
    "    from pandas_adv import (  # type: ignore  # pylint: disable=import-error\n",
    "        filter_by_high_revenue,\n",
    "        filter_by_product_and_region,\n",
    "        handle_missing_data,\n",
    "        load_sales_data,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_pipeline(\n",
    "    data_path: Path, threshold: float, product: str, region: str, missing_strategy: str\n",
    ") -> Callable[[], None]:\n",
    "    \"\"\"Return a callable that executes the common lesson workflow.\"\"\"\n",
    "\n",
    "    def pipeline() -> None:\n",
    "        df = load_sales_data(str(data_path))\n",
    "        if df is None or df.empty:\n",
    "            raise ValueError(\n",
    "                f\"Sales data could not be loaded from {data_path}. Ensure the CSV exists\"\n",
    "                \" and contains data.\"\n",
    "            )\n",
    "\n",
    "        filter_by_high_revenue(df, threshold)\n",
    "        filter_by_product_and_region(df, product, region)\n",
    "        handle_missing_data(df, strategy=missing_strategy)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\n",
    "        \"--mode\",\n",
    "        choices=(\"cprofile\", \"timeit\"),\n",
    "        default=\"cprofile\",\n",
    "        help=\"Profiling backend to use (default: cprofile)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--threshold\",\n",
    "        type=float,\n",
    "        default=50_000,\n",
    "        help=\"Revenue threshold used in filter_by_high_revenue\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--product\",\n",
    "        default=\"Laptop\",\n",
    "        help=\"Product name used for filter_by_product_and_region\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--region\",\n",
    "        default=\"North\",\n",
    "        help=\"Region used for filter_by_product_and_region\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--missing-strategy\",\n",
    "        choices=(\"drop\", \"fill\"),\n",
    "        default=\"fill\",\n",
    "        help=\"Strategy used when calling handle_missing_data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--repeat\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Number of timing repeats when --mode=timeit\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--number\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of calls per repeat when --mode=timeit\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_path = Path(__file__).resolve().parent / \"sales_data.csv\"\n",
    "    pipeline = build_pipeline(\n",
    "        data_path=data_path,\n",
    "        threshold=args.threshold,\n",
    "        product=args.product,\n",
    "        region=args.region,\n",
    "        missing_strategy=args.missing_strategy,\n",
    "    )\n",
    "\n",
    "    profile_report, timing_report = profile_callable(\n",
    "        pipeline,\n",
    "        mode=args.mode,\n",
    "        repeat=args.repeat,\n",
    "        number=args.number,\n",
    "    )\n",
    "    print_report(profile_report=profile_report, timing_report=timing_report)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
