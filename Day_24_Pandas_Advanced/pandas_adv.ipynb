{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4dd6389",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 24: Advanced Pandas - Working with Real Data\n",
    "\n",
    "You'll rarely create data from scratch. The most common workflow is to load data from external sources like CSV files. Today, we'll focus on loading data and using powerful methods to select, filter, and clean it.\n",
    "\n",
    "## Advanced Selection: `.loc` and `.iloc`\n",
    "\n",
    "For complex selections, Pandas provides two powerful indexers:\n",
    "\n",
    "- **`.loc` (Label-based):** Selects data based on **row and column labels**.\n",
    "  ```python\n",
    "  # Selects row with index label 3, and only the 'Product' and 'Revenue' columns\n",
    "  subset = df.loc[3, ['Product', 'Revenue']]\n",
    "  ```\n",
    "- **`.iloc` (Integer-position based):** Selects data based on its **integer position**.\n",
    "  ```python\n",
    "  # Selects the first three rows (positions 0, 1, 2) and the first two columns (0, 1)\n",
    "  subset = df.iloc[0:3, 0:2]\n",
    "  ```\n",
    "\n",
    "## Conditional Filtering (Boolean Indexing)\n",
    "\n",
    "This is one of the most powerful features of Pandas. You can filter your DataFrame by providing a boolean (`True`/`False`) condition.\n",
    "\n",
    "```python\n",
    "# Find all high-revenue sales from the 'North' region\n",
    "# Note the parentheses around each condition\n",
    "high_rev_north = df[(df['Revenue'] > 50000) & (df['Region'] == 'North')]\n",
    "```\n",
    "\n",
    "## Handling Missing Data\n",
    "\n",
    "Real-world data is often messy and has missing values, represented as `NaN`.\n",
    "\n",
    "- `df.isnull().sum()`: A crucial command to count missing values in each column.\n",
    "- `df.dropna()`: Drops rows that contain any missing values.\n",
    "- `df.fillna(value)`: Fills missing values with a specified value (e.g., 0 or the column's mean).\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `pandas_adv.py`, has been refactored to place each advanced operation into its own testable function.\n",
    "\n",
    "1. **Review the Code:** Open `Day_24_Pandas_Advanced/pandas_adv.py`. Examine functions like `filter_by_high_revenue()`, `filter_by_product_and_region()`, and `handle_missing_data()`.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script to see the functions in action:\n",
    "   ```bash\n",
    "   python Day_24_Pandas_Advanced/pandas_adv.py\n",
    "   ```\n",
    "   If the CSV file is missing, the refactored `handle_missing_data()` helper now raises\n",
    "   a clear `ValueError` explaining how to restore the dataset before continuing.\n",
    "1. **Run the Tests:** The tests use a sample DataFrame created in memory, so they don't depend on the external CSV file.\n",
    "   ```bash\n",
    "   pytest tests/test_day_24.py\n",
    "   ```\n",
    "\n",
    "## âœ¨ Interactive Plotly Visualisations\n",
    "\n",
    "Plotly chart builders now sit alongside the existing data-wrangling helpers:\n",
    "\n",
    "- `build_revenue_by_region_bar_chart()` aggregates revenue totals for each region and renders an interactive bar chart.\n",
    "- `build_units_vs_price_scatter()` plots price sensitivity using `Units Sold` on the y-axis and encodes the point colour scale for quick outlier detection.\n",
    "\n",
    "To experiment locally:\n",
    "\n",
    "1. Install notebook dependencies if you have not done so already:\n",
    "   ```bash\n",
    "   pip install notebook plotly\n",
    "   ```\n",
    "1. Launch Jupyter from the project root and open the companion notebook:\n",
    "   ```bash\n",
    "   jupyter notebook Day_24_Pandas_Advanced/pandas_adv_interactive.ipynb\n",
    "   ```\n",
    "1. Run the cells to compare the quick Matplotlib baseline with the interactive Plotly versions. Hover, filter, and export the Plotly figures directly from the notebook toolbar.\n",
    "\n",
    "## ðŸ”¬ Profiling the Workflow\n",
    "\n",
    "Curious about where Pandas spends its time? Launch the shared profiling helper to benchmark the lesson workflow:\n",
    "\n",
    "```bash\n",
    "python Day_24_Pandas_Advanced/profile_pandas_adv.py --mode cprofile\n",
    "python Day_24_Pandas_Advanced/profile_pandas_adv.py --mode timeit --repeat 5 --number 3\n",
    "```\n",
    "\n",
    "The first command prints a truncated `cProfile` report. In our baseline run the CSV load (`pandas.read_csv`) and the follow-up cleaning call (`handle_missing_data`) dominated the runtime, confirming that disk I/O and DataFrame materialisation are the hot spots.ã€732170â€ L1-L28ã€‘ The `timeit` helper highlights how quickly the full workflow executes once the operating system cache is warmâ€”about 3 ms per iteration on average across five repeats.ã€af7429â€ L1-L7ã€‘ If you plan to reuse the dataset across multiple analyses, load the CSV once and reuse the DataFrame rather than calling `read_csv` inside a tight loop.\n",
    "\n",
    "## ðŸ’» Exercises: Day 24\n",
    "\n",
    "1. **Load and Inspect:**\n",
    "\n",
    "   - In a new script (`my_solutions_24.py`), import `pandas as pd` and `pathlib`.\n",
    "   - Load the `sales_data.csv` file (located in the `Day_24_Pandas_Advanced` directory) into a DataFrame.\n",
    "   - Use `.head()` and `.info()` to inspect the loaded data.\n",
    "\n",
    "1. **Select and Filter:**\n",
    "\n",
    "   - Using the DataFrame from the previous exercise, import and use the `filter_by_product_and_region` function to find all sales of `\"Mouse\"` in the `\"South\"` region. Print the result.\n",
    "   - Import and use the `filter_by_high_revenue` function to find all sales with revenue over $70,000.\n",
    "\n",
    "1. **Basic Data Cleaning:**\n",
    "\n",
    "   - Import the `handle_missing_data` function.\n",
    "   - Call the function twice on your DataFrame:\n",
    "     - Once with `strategy='drop'` to remove rows with missing data.\n",
    "     - Once with `strategy='fill'` to fill missing revenue with the column average.\n",
    "   - Print the `.shape` of both resulting DataFrames to see how they differ.\n",
    "\n",
    "ðŸŽ‰ **Excellent work!** You're now working with data like a real analystâ€”loading it from files, inspecting it, and using powerful tools to filter and clean it. These are foundational skills for every data analysis project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaed03b",
   "metadata": {},
   "source": [
    "Day 24: Advanced Pandas - Working with Real Data (Refactored)\n",
    "\n",
    "This script demonstrates loading data from a CSV file and\n",
    "using advanced selection and cleaning techniques with Pandas,\n",
    "refactored into testable functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def load_sales_data(file_path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Loads sales data from a CSV file into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: The file was not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def select_by_label(\n",
    "    df: pd.DataFrame, index_label: Any, columns: List[str]\n",
    ") -> Optional[pd.Series]:\n",
    "    \"\"\"Selects data by row label and column names using .loc.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    try:\n",
    "        return df.loc[index_label, columns]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def select_by_position(\n",
    "    df: pd.DataFrame, row_pos: int, col_slice: slice\n",
    ") -> Optional[pd.Series]:\n",
    "    \"\"\"Selects data by integer position using .iloc.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    try:\n",
    "        return df.iloc[row_pos, col_slice]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def filter_by_high_revenue(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"Filters the DataFrame for rows where Revenue exceeds a threshold.\"\"\"\n",
    "    if df is None or \"Revenue\" not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    return df[df[\"Revenue\"] > threshold]\n",
    "\n",
    "\n",
    "def filter_by_product_and_region(\n",
    "    df: pd.DataFrame, product: str, region: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filters the DataFrame for a specific product and region.\"\"\"\n",
    "    if df is None or \"Product\" not in df.columns or \"Region\" not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    return df[(df[\"Product\"] == product) & (df[\"Region\"] == region)]\n",
    "\n",
    "\n",
    "def handle_missing_data(\n",
    "    df: Optional[pd.DataFrame], strategy: str = \"drop\", fill_value=None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Handles missing data by either dropping rows or filling with a value.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\n",
    "            \"No sales data is available. Ensure the CSV exists and contains rows before\"\n",
    "            \" calling handle_missing_data.\"\n",
    "        )\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    if strategy == \"drop\":\n",
    "        return df_copy.dropna()\n",
    "    elif strategy == \"fill\":\n",
    "        if fill_value is None:\n",
    "            # Default to filling with the mean for numeric columns\n",
    "            for col in df_copy.columns:\n",
    "                if pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "                    df_copy[col] = df_copy[col].fillna(df_copy[col].mean())\n",
    "        else:\n",
    "            df_copy = df_copy.fillna(fill_value)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def build_revenue_by_region_bar_chart(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"Build an interactive bar chart comparing revenue across regions.\"\"\"\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"DataFrame must not be empty\")\n",
    "    if not {\"Region\", \"Revenue\"}.issubset(df.columns):\n",
    "        raise KeyError(\"DataFrame must include 'Region' and 'Revenue' columns\")\n",
    "\n",
    "    regional_revenue = (\n",
    "        df.groupby(\"Region\", dropna=False)[\"Revenue\"]\n",
    "        .sum(min_count=1)\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    figure = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(\n",
    "                x=regional_revenue.index.astype(str),\n",
    "                y=regional_revenue.values,\n",
    "                marker_color=\"#00A1D6\",\n",
    "                hovertemplate=\"Region: %{x}<br>Revenue: %{y:$,.0f}<extra></extra>\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    figure.update_layout(\n",
    "        title=\"Revenue by Region\",\n",
    "        xaxis_title=\"Region\",\n",
    "        yaxis_title=\"Total Revenue\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return figure\n",
    "\n",
    "\n",
    "def build_units_vs_price_scatter(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"Return a scatter plot showing how pricing relates to units sold.\"\"\"\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"DataFrame must not be empty\")\n",
    "    required_columns = {\"Units Sold\", \"Price\", \"Product\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        missing = \", \".join(sorted(required_columns - set(df.columns)))\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    figure = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                x=df[\"Price\"],\n",
    "                y=df[\"Units Sold\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=df[\"Units Sold\"],\n",
    "                    colorscale=\"Viridis\",\n",
    "                    showscale=True,\n",
    "                ),\n",
    "                text=df[\"Product\"],\n",
    "                hovertemplate=(\n",
    "                    \"Product: %{text}<br>Price: %{x:$,.0f}<br>Units Sold: %{y}<extra></extra>\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    figure.update_layout(\n",
    "        title=\"Units Sold vs. Price\",\n",
    "        xaxis_title=\"Price\",\n",
    "        yaxis_title=\"Units Sold\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return figure\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate advanced Pandas operations.\"\"\"\n",
    "    print(\"--- Loading and Inspecting sales_data.csv ---\")\n",
    "    resource_dir = Path(__file__).resolve().parent\n",
    "    data_path = resource_dir / \"sales_data.csv\"\n",
    "    df = load_sales_data(str(data_path))\n",
    "\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        print(\"--- Advanced Data Selection ---\")\n",
    "        product_3 = select_by_label(df, 3, [\"Product\", \"Revenue\"])\n",
    "        print(f\"Product and Revenue for row index 3 (using .loc):\\n{product_3}\\n\")\n",
    "\n",
    "        row_0 = select_by_position(df, 0, slice(0, 3))\n",
    "        print(f\"First row, first 3 columns (using .iloc):\\n{row_0}\\n\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        print(\"--- Conditional Filtering ---\")\n",
    "        high_revenue_df = filter_by_high_revenue(df, 50000)\n",
    "        print(f\"Found {len(high_revenue_df)} sales with revenue > $50,000.\")\n",
    "\n",
    "        laptop_north_df = filter_by_product_and_region(df, \"Laptop\", \"North\")\n",
    "        print(f\"Found {len(laptop_north_df)} 'Laptop' sales in the 'North' region.\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        print(\"--- Handling Missing Data ---\")\n",
    "        print(f\"Original shape: {df.shape}\")\n",
    "        print(f\"Missing values count:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        df_dropped = handle_missing_data(df, strategy=\"drop\")\n",
    "        print(f\"Shape after dropping missing rows: {df_dropped.shape}\")\n",
    "\n",
    "        df_filled = handle_missing_data(df, strategy=\"fill\")\n",
    "        print(\n",
    "            f\"Missing values after filling with mean:\\n{df_filled.isnull().sum().sum()}\"\n",
    "        )\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
